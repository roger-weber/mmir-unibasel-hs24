{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from text\n",
    "\n",
    "We look at the classical method to describe text documents. We will improve these descriptors in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (8.1.5)\n",
      "Requirement already satisfied: pandas in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: boto3 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.35.18)\n",
      "Requirement already satisfied: opencv-python in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.10.0.84)\n",
      "Requirement already satisfied: scikit-image in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.24.0)\n",
      "Requirement already satisfied: matplot in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.1.9)\n",
      "Requirement already satisfied: PyPDF2 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: unidecode in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.3.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 2)) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 2)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 2)) (3.0.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.18 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from boto3->-r requirements.txt (line 5)) (1.35.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from boto3->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from boto3->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: pyloco>=0.0.134 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplot->-r requirements.txt (line 8)) (0.0.139)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplot->-r requirements.txt (line 8)) (3.9.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.18->boto3->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: decorator in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplotlib>=3.1.1->matplot->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplotlib>=3.1.1->matplot->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplotlib>=3.1.1->matplot->-r requirements.txt (line 8)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplotlib>=3.1.1->matplot->-r requirements.txt (line 8)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from matplotlib>=3.1.1->matplot->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: ushlex in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (0.99.1)\n",
      "Requirement already satisfied: websocket-client in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: twine in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (5.1.1)\n",
      "Requirement already satisfied: typing in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.7.4.3)\n",
      "Requirement already satisfied: SimpleWebSocketServer in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 2)) (0.2.3)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: readme-renderer>=35.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (44.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (8.5.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: rfc3986>=1.4.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (13.8.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from importlib-metadata>=3.6->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.20.1)\n",
      "Requirement already satisfied: jaraco.classes in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (4.0.2)\n",
      "Requirement already satisfied: jaraco.context in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: nh3>=0.2.14 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (0.2.18)\n",
      "Requirement already satisfied: docutils>=0.21.2 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (0.21.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: more-itertools in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from jaraco.classes->keyring>=15.1->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (10.5.0)\n",
      "Requirement already satisfied: backports.tarfile in /Users/drweb/projects/mmir-unibasel/.venv/lib/python3.11/site-packages (from jaraco.context->keyring>=15.1->twine->pyloco>=0.0.134->matplot->-r requirements.txt (line 8)) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, JSON\n",
    "import urllib.request\n",
    "import os, re\n",
    "from PyPDF2 import PdfReader\n",
    "from unidecode import unidecode\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import *\n",
    "import math\n",
    "import random\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text from file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"https://dmi.unibas.ch/fileadmin/user_upload/dmi/Studium/Computer_Science/Vorlesungen_HS23/Multimedia_Retrieval/HS24/03_ClassicalTextRetrieval.pdf\"\n",
    "local_filename = 'example.pdf'\n",
    "\n",
    "# unless local file already exists, download the file\n",
    "if not os.path.exists(local_filename):\n",
    "    urllib.request.urlretrieve(uri, local_filename)\n",
    "    print(f\"File downloaded and saved as {local_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Computer Science / 15731 - 01 / 2024 Multimedia Retrieval Chapter 1: Introduction Dr. Roger Weber, roger.weber@gmail.com 1.1 Motivation 1.2 Generic Retrieval Process 1.3 Metadata and How It Can Help 1.4 References Links 1.1 Motivation 1.2 Generic Retrieval Process 1.3 Metadata and How It Can Help 1.4 References & Links Course ID 15731 - 01 Lecturer Dr. Roger Weber, roger.weber@gmail.com Time Friday 15:15 - 18:00 (1 st /2 nd hour for theory, 3 rd hour for exercise & practice → bring your own laptop) Note: changes are announced on web site and / or per e - mail ahead of lectures Location Physical presence: Seminarraum 05.002, Spiegelgasse 5 If physical presence is not possible, we use Zoom Meetings. Please check the schedule for updates. During physical presence lectures, no Zoom meetings and no video recordings are available. Prerequisites Basics of programming (Python preferred) Mathematical foundations (for some parts) Content Introduction to multimedia retrieval with a focus on classical text retrieval, web retrieval, extraction and machine learning of features for images, audio, and video, index structures, search algorithms, and concrete implementations. The course is touching on classical and current information retrieval techniques and search algorithms. Exam Oral exam (30 minutes) on January 10, 14, 17, 21, 24 Credit Points 6 Grades From 1 to 6 with 0.5 steps. 4.0 or higher required to pass exam. Homepage WEB: https://dmi.unibas.ch/de/studium/computer - science - informatik/lehrangebot - hs24/15731 - lecture - multimedia - retrieval/ ADAM: https://adam.unibas.ch/goto_adam_crs_1738202.html All materials are published in advance. Practical exercises to be submitted to ADAM Structure of the class Foundation 1 Introduction We cover motivation, a summary of history, the generic retrieval process and its variations, a quick overview of metadata, and view demos to get us started 2 Evaluation We focus on evaluating and comparing retrieval systems and machine learning approaches. This serves as the basis for assessing the effectiveness of the methods covered in most of the chapters 11 ML Methods* We cover essential machine learning methods as needed for content analysis and the extraction of metadata items. As we progress through the course, we will visit individual chapters as need Text & Web Retrieval 3 Classic We explore classical text retrieval models, with a particular emphasis on vector space retrieval. We also delve into Lucene, OpenSearch and Elasticsearch which showcase the capabilities of these models 4 Advanced We examine natural language processing using NLTK as an example. Additionally, we explore contemporary methods for creating embeddings and leveraging generative AI to improve results 5 Web & Social We focus on web and social media retrieval, particularly examining methods to influence rankings based on the relationships between documents 6 Vector Search We explore the challenge of searching through embeddings and feature vectors. We discuss the “curse of dimensionality” and study contemporary techniques used by products like Lucene, OpenSearch, and Elasticsearch Image Retrieval 7 Basic We cover the human perception of visual signal information and examine several algorithms for extracting features that describe color, texture, and shape aspects found in the images 8 Advanced We delve into neural networks and explore the concept of deep learning. We apply these techniques to extract higher - level features, including classifications, facial recognition, and object bounding boxes Audio Retrieval 9 Basic We cover the human perception of audio signals and study various algorithms for extracting features in both the time and frequency domains. Additionally, we delve into the unique case of extracting musical features Video Retrieval 10 Basic We discuss fundamental elements of motion detection and video segmentation. Specifically, we focus on identifying shot and scene boundaries in videos For exams, Chapter 11 requi..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_text_from_pdf(file_name: str) -> str:\n",
    "    pages = []\n",
    "\n",
    "    def visitor_text(text, cm, tm, fontDict, fontSize):\n",
    "        y = tm[5]\n",
    "        if y > 20 and len(text) > 0:\n",
    "            # replace \\n and multiple spaces (\\s*) with a single space\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "            text = re.sub(r'\\[\\d+\\]|➢|•', '', text)\n",
    "            parts.append(text)\n",
    "\n",
    "    # read the PDF and extract all texts (do some post-processing with above function)\n",
    "    reader = PdfReader(file_name)\n",
    "    for page in reader.pages:\n",
    "        parts = []\n",
    "        page.extract_text(visitor_text=visitor_text)\n",
    "        pages.append(re.sub(r'\\s+',' ', \" \".join(parts)).strip())\n",
    "\n",
    "    # merge text blocks and clean-up\n",
    "    return pages\n",
    "\n",
    "pages = extract_text_from_pdf(local_filename)\n",
    "text = re.sub(r'\\s+',' ', \" \".join(pages))\n",
    "display(Markdown(text[0:4000]+\"...\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    text = re.sub(r'[^\\w\\-]+', ' ', text)\n",
    "    tokens = []\n",
    "    for token in text.split(' '):\n",
    "        token = unidecode(token.strip().lower())\n",
    "        if len(token) < 2: continue\n",
    "        if not(re.match(r'^[a-zA-Z][\\w\\-\\.]*$', token)): continue\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "tokens = tokenize(text)\n",
    "print(\"\\n\".join(tokens[0:20]))\n",
    "print(f'...\\n\\nextracted {len(tokens)} tokens from text with {len(set(tokens))} unique tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see which terms appear most often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(text)\n",
    "print_table(Counter(tokens).most_common(20),['token', 'frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply porter stemming to reduce words to a common stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def reduce_to_stems(tokens):\n",
    "    return list(map(lambda token: porter_stemmer.stem(token), tokens))\n",
    "\n",
    "tokens = reduce_to_stems(tokenize(text))\n",
    "print_table(Counter(tokens).most_common(20),['token', 'frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate the stopwords as they do not describe the content of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_stopwords(tokens):\n",
    "    return [token for token in tokens if not(token in stopwords['english'])]\n",
    "\n",
    "tokens = tokenize(text)\n",
    "count = len(tokens)\n",
    "tokens = reduce_to_stems(eliminate_stopwords(tokens))\n",
    "print(f'{count-len(tokens)} stopwords removed ({(count-len(tokens))/count*100:.2f}%)')\n",
    "print(f'{len(tokens)} non-stopword tokens remain with {len(set(tokens))} unique tokens')\n",
    "print_table(Counter(tokens).most_common(20),['token', 'frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We describe each page separately and treat them as mini-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [reduce_to_stems(eliminate_stopwords(tokenize(text))) for text in pages]\n",
    "\n",
    "n = 10\n",
    "print_table(\n",
    "    [\n",
    "        [\n",
    "            i+1,\n",
    "            \" \".join(collection[i])\n",
    "        ] for i in range(n)\n",
    "    ],\n",
    "    [\"page\", \"tokens\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-of-words summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_words(tokens):\n",
    "    return set(tokens)\n",
    "\n",
    "n = 10\n",
    "print_table(\n",
    "    [\n",
    "        [\n",
    "            f\"{i+1}\",\n",
    "            \", \".join(sorted(set_of_words(collection[i])))\n",
    "        ] for i in range(n)\n",
    "    ],\n",
    "    [\"page\", \"set of words\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokens):\n",
    "    return dict(Counter(tokens))\n",
    "\n",
    "n = 10\n",
    "print_table(\n",
    "    [\n",
    "        [\n",
    "            f\"{i+1}\",\n",
    "            \", \".join([f'{x[0]}:{x[1]}' for x in sorted(bag_of_words(collection[i]).items())])\n",
    "        ] for i in range(n)\n",
    "    ],\n",
    "    [\"page\", \"bag of words\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words require document frequency and idf weigths for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(N, df):\n",
    "    return math.log10((N + 1) / (df + 1))\n",
    "\n",
    "terms = defaultdict(int)\n",
    "for page in collection:\n",
    "    # go through each distinct term on this page\n",
    "    for term in set(page):\n",
    "        terms[term] += 1\n",
    "vocabulary = {term: {\"df\": count, \"idf\": idf(len(collection), count)} for term, count in terms.items()}\n",
    "\n",
    "n = 20\n",
    "sample = sorted(random.sample(list(vocabulary.items()), n), key=lambda x: x[1][\"idf\"], reverse=True)\n",
    "print_table(\n",
    "    [\n",
    "        [x[0], f'{x[1][\"df\"]} / {len(collection)}', f'{x[1][\"idf\"]:.3f}'] for x in sample\n",
    "    ],\n",
    "    [\"Term\", \"df\", \"idf\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can compute the bag-of-word representation for vector space retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def bag_of_words_idf(tokens, vocabulary):\n",
    "    terms = dict(Counter(tokens))\n",
    "    return map(lambda w: (w[0], w[1] * vocabulary[w[0]]['idf']), terms.items())\n",
    "\n",
    "n = 10\n",
    "print_table(\n",
    "    [\n",
    "        [\n",
    "            f\"{i+1}\",\n",
    "            \", \".join([f'{x[0]}:{x[1]:.2f}' for x in sorted(bag_of_words_idf(collection[i], vocabulary))])\n",
    "        ] for i in range(n)\n",
    "    ],\n",
    "    [\"page\", \"bag of words (vector space retrieval)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
